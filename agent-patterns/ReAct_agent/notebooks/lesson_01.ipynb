{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReAct Agent\n",
    "\n",
    "ReAct is a pattern that combines Reasoning and Acting. It is a way to make an agent more flexible and adaptable. The reasoning part is the agent's ability to think about the problem and the acting part is the agent's ability to take action using the tools provided to it.\n",
    "\n",
    "In the last session, we created a tool calling agent that could call a tool to calculate the area of a rectangle. In this session, we will create a ReAct agent will be able to utilize some of this tool calling logic to take actions.\n",
    "\n",
    "\n",
    "### Getting Started\n",
    "\n",
    "To get started, let's bring in some of the code from the las session in here so we can make use of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Dict, Any\n",
    "import json\n",
    "\n",
    "def extract_function_metadata(function: Callable) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Creates a metadata dictionary from a function's signature.\n",
    "    \n",
    "    Parameters:\n",
    "        function: The target function to analyze\n",
    "        \n",
    "    Returns:\n",
    "        A dictionary containing the function's name, documentation, and parameter specifications\n",
    "    \"\"\"\n",
    "    # Initialize the basic structure\n",
    "    metadata = {\n",
    "        \"name\": function.__name__,\n",
    "        \"description\": function.__doc__,\n",
    "        \"parameters\": {\"properties\": {}}\n",
    "    }\n",
    "    \n",
    "    # Extract parameter types (excluding return annotation)\n",
    "    parameter_types = {\n",
    "        param_name: {\"type\": param_type.__name__}\n",
    "        for param_name, param_type in function.__annotations__.items()\n",
    "        if param_name != \"return\"\n",
    "    }\n",
    "    \n",
    "    # Add parameters to metadata\n",
    "    metadata[\"parameters\"][\"properties\"] = parameter_types\n",
    "    return metadata\n",
    "\n",
    "def convert_argument_types(tool_invocation: Dict[str, Any], function_spec: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Ensures all arguments match their expected types according to the function specification.\n",
    "    \n",
    "    Parameters:\n",
    "        tool_invocation: Dictionary with the tool name and arguments\n",
    "        function_spec: Dictionary containing the expected parameter types\n",
    "        \n",
    "    Returns:\n",
    "        Updated tool invocation with correctly typed arguments\n",
    "    \"\"\"\n",
    "    expected_params = function_spec[\"parameters\"][\"properties\"]\n",
    "    \n",
    "    # Type conversion mapping\n",
    "    type_converters = {\n",
    "        \"int\": int,\n",
    "        \"str\": str,\n",
    "        \"bool\": bool,\n",
    "        \"float\": float\n",
    "    }\n",
    "    \n",
    "    # Convert each argument to its expected type if needed\n",
    "    for arg_name, arg_value in tool_invocation[\"arguments\"].items():\n",
    "        target_type = expected_params[arg_name].get(\"type\")\n",
    "        if not isinstance(arg_value, type_converters[target_type]):\n",
    "            tool_invocation[\"arguments\"][arg_name] = type_converters[target_type](arg_value)\n",
    "            \n",
    "    return tool_invocation\n",
    "\n",
    "class Tool:\n",
    "    \"\"\"\n",
    "    Wrapper class that encapsulates a function as a callable tool.\n",
    "    \n",
    "    Attributes:\n",
    "        name: Tool identifier\n",
    "        function: The underlying function\n",
    "        specification: JSON-formatted function metadata\n",
    "    \"\"\"\n",
    "    def __init__(self, name: str, function: Callable, specification: str):\n",
    "        self.name = name\n",
    "        self.function = function\n",
    "        self.specification = specification\n",
    "        \n",
    "    def __str__(self):\n",
    "        return self.specification\n",
    "        \n",
    "    def execute(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Runs the wrapped function with the provided arguments.\n",
    "        \n",
    "        Parameters:\n",
    "            **kwargs: Arguments to pass to the function\n",
    "            \n",
    "        Returns:\n",
    "            The function's result\n",
    "        \"\"\"\n",
    "        return self.function(**kwargs)\n",
    "\n",
    "def tool(function: Callable) -> Tool:\n",
    "    \"\"\"\n",
    "    Decorator that transforms a regular function into a Tool instance.\n",
    "    \n",
    "    Parameters:\n",
    "        function: The function to convert into a tool\n",
    "        \n",
    "    Returns:\n",
    "        A fully configured Tool object\n",
    "    \"\"\"\n",
    "    def create_tool():\n",
    "        metadata = extract_function_metadata(function)\n",
    "        return Tool(\n",
    "            name=metadata.get(\"name\"),\n",
    "            function=function,\n",
    "            specification=json.dumps(metadata)\n",
    "        )\n",
    "    \n",
    "    return create_tool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from typing import List, Dict, Any, Callable\n",
    "from colorama import init, Fore, Style\n",
    "\n",
    "# Initialize colorama\n",
    "init(autoreset=True)\n",
    "\n",
    "class ToolCallingAgent:\n",
    "    \"\"\"\n",
    "    An agent that integrates language models with function-calling tools.\n",
    "    \n",
    "    This class manages the interaction between a language model and a set of tools,\n",
    "    allowing the model to decide when to call functions and processing the results.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, llm: Callable, system_prompt: str, tools: List[Any]):\n",
    "        \"\"\"\n",
    "        Initialize an AI agent with a language model and tools.\n",
    "        \n",
    "        Args:\n",
    "            llm: Function that takes a prompt string and returns a response\n",
    "            system_prompt: Instructions for guiding the language model's behavior\n",
    "            tools: List of Tool objects that the agent can use\n",
    "        \"\"\"\n",
    "        self.model = llm\n",
    "        self.system_prompt = system_prompt\n",
    "        self.tools = {tool.name: tool for tool in tools}\n",
    "        self.conversation_history = []\n",
    "        print(f\"{Fore.GREEN}ToolCallingAgent initialized with {len(tools)} tools{Style.RESET_ALL}\")\n",
    "        \n",
    "    def format_tools_for_prompt(self) -> str:\n",
    "        \"\"\"Format all available tools into a format the language model can understand.\"\"\"\n",
    "        tools_json = []\n",
    "        for tool in self.tools.values():\n",
    "            try:\n",
    "                # Use the specification provided by the @tool decorator\n",
    "                tools_json.append(json.loads(tool.specification))\n",
    "            except (json.JSONDecodeError, AttributeError):\n",
    "                # Fallback for tools without proper specification\n",
    "                tools_json.append({\n",
    "                    \"name\": tool.name,\n",
    "                    \"description\": getattr(tool, \"description\", \"No description available\"),\n",
    "                    \"parameters\": {\"properties\": {}}\n",
    "                })\n",
    "        \n",
    "        print(f\"{Fore.CYAN}Formatted {len(tools_json)} tools for LLM prompt{Style.RESET_ALL}\")\n",
    "        return f\"<tools>\\n{json.dumps(tools_json, indent=2)}\\n</tools>\"\n",
    "    \n",
    "    def extract_tool_calls(self, response: str) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Parse the language model's response to extract tool call requests.\n",
    "        \n",
    "        Args:\n",
    "            response: The text response from the language model\n",
    "            \n",
    "        Returns:\n",
    "            A list of tool call dictionaries with 'name' and 'arguments' keys\n",
    "        \"\"\"\n",
    "        tool_calls = []\n",
    "        pattern = r\"<tool_call>(.*?)</tool_call>\"\n",
    "        matches = re.findall(pattern, response, re.DOTALL)\n",
    "        \n",
    "        for match in matches:\n",
    "            try:\n",
    "                tool_call = json.loads(match.strip())\n",
    "                if \"name\" in tool_call and \"arguments\" in tool_call:\n",
    "                    tool_calls.append(tool_call)\n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "        \n",
    "        if tool_calls:\n",
    "            print(f\"{Fore.YELLOW}Extracted {len(tool_calls)} tool call(s) from LLM response{Style.RESET_ALL}\")\n",
    "        else:\n",
    "            print(f\"{Fore.YELLOW}No tool calls found in LLM response{Style.RESET_ALL}\")\n",
    "                \n",
    "        return tool_calls\n",
    "    \n",
    "    def execute_tool(self, tool_call: Dict[str, Any]) -> Any:\n",
    "        \"\"\"\n",
    "        Execute a tool based on the model's request.\n",
    "        \n",
    "        Args:\n",
    "            tool_call: Dictionary with 'name' and 'arguments' for the tool\n",
    "            \n",
    "        Returns:\n",
    "            The result from executing the tool\n",
    "        \"\"\"\n",
    "        tool_name = tool_call.get(\"name\")\n",
    "        arguments = tool_call.get(\"arguments\", {})\n",
    "        \n",
    "        if tool_name not in self.tools:\n",
    "            print(f\"{Fore.RED}Error: Tool '{tool_name}' not found{Style.RESET_ALL}\")\n",
    "            return f\"Error: Tool '{tool_name}' not found\"\n",
    "            \n",
    "        tool = self.tools[tool_name]\n",
    "        print(f\"{Fore.MAGENTA}Executing tool: {tool_name} with arguments: {json.dumps(arguments)}{Style.RESET_ALL}\")\n",
    "        \n",
    "        # Validate and convert argument types using the tool's specification\n",
    "        try:\n",
    "            if hasattr(tool, \"specification\"):\n",
    "                tool_spec = json.loads(tool.specification)\n",
    "                validated_args = self.convert_argument_types(\n",
    "                    {\"arguments\": arguments}, \n",
    "                    tool_spec\n",
    "                )[\"arguments\"]\n",
    "                arguments = validated_args\n",
    "                print(f\"{Fore.BLUE}Arguments validated and converted to appropriate types{Style.RESET_ALL}\")\n",
    "        except (json.JSONDecodeError, AttributeError, KeyError) as e:\n",
    "            print(f\"{Fore.RED}Error validating arguments: {str(e)}{Style.RESET_ALL}\")\n",
    "            # Continue with original arguments if validation fails\n",
    "            pass\n",
    "            \n",
    "        try:\n",
    "            # Handle execution based on the tool interface\n",
    "            # First try the execute method for tools created with the @tool decorator\n",
    "            if hasattr(tool, \"execute\"):\n",
    "                print(f\"{Fore.GREEN}Calling tool.execute() method{Style.RESET_ALL}\")\n",
    "                return tool.execute(**arguments)\n",
    "            # Then try the function attribute which is used by the @tool decorator\n",
    "            elif hasattr(tool, \"function\"):\n",
    "                print(f\"{Fore.GREEN}Calling tool.function() method{Style.RESET_ALL}\")\n",
    "                return tool.function(**arguments)\n",
    "            # Fall back to run method\n",
    "            elif hasattr(tool, \"run\"):\n",
    "                print(f\"{Fore.GREEN}Calling tool.run() method{Style.RESET_ALL}\")\n",
    "                return tool.run(**arguments)\n",
    "            # Last resort: call the tool directly if it's callable\n",
    "            elif callable(tool):\n",
    "                print(f\"{Fore.GREEN}Calling tool directly{Style.RESET_ALL}\")\n",
    "                return tool(**arguments)\n",
    "            else:\n",
    "                print(f\"{Fore.RED}Error: Tool '{tool_name}' is not callable{Style.RESET_ALL}\")\n",
    "                return f\"Error: Tool '{tool_name}' is not callable\"\n",
    "        except Exception as e:\n",
    "            print(f\"{Fore.RED}Error executing {tool_name}: {str(e)}{Style.RESET_ALL}\")\n",
    "            return f\"Error executing {tool_name}: {str(e)}\"\n",
    "    \n",
    "    def convert_argument_types(self, tool_call: Dict[str, Any], tool_spec: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Convert arguments to their expected types based on tool specification.\n",
    "        \n",
    "        Args:\n",
    "            tool_call: Dictionary containing arguments to convert\n",
    "            tool_spec: Tool specification with expected types\n",
    "            \n",
    "        Returns:\n",
    "            Updated tool call with properly typed arguments\n",
    "        \"\"\"\n",
    "        if \"parameters\" not in tool_spec or \"properties\" not in tool_spec[\"parameters\"]:\n",
    "            return tool_call\n",
    "            \n",
    "        properties = tool_spec[\"parameters\"][\"properties\"]\n",
    "        \n",
    "        # Standard type converters\n",
    "        type_mapping = {\n",
    "            \"int\": int,\n",
    "            \"str\": str,\n",
    "            \"bool\": bool,\n",
    "            \"float\": float,\n",
    "            \"integer\": int,\n",
    "            \"string\": str,\n",
    "            \"boolean\": bool,\n",
    "            \"number\": float\n",
    "        }\n",
    "        \n",
    "        for arg_name, arg_value in tool_call[\"arguments\"].items():\n",
    "            if arg_name in properties and \"type\" in properties[arg_name]:\n",
    "                expected_type = properties[arg_name][\"type\"]\n",
    "                \n",
    "                if expected_type in type_mapping:\n",
    "                    converter = type_mapping[expected_type]\n",
    "                    try:\n",
    "                        # Only convert if types don't match\n",
    "                        if not isinstance(arg_value, converter):\n",
    "                            print(f\"{Fore.BLUE}Converting argument '{arg_name}' from {type(arg_value).__name__} to {expected_type}{Style.RESET_ALL}\")\n",
    "                            tool_call[\"arguments\"][arg_name] = converter(arg_value)\n",
    "                    except (ValueError, TypeError) as e:\n",
    "                        print(f\"{Fore.RED}Type conversion error for '{arg_name}': {str(e)}{Style.RESET_ALL}\")\n",
    "                        # Keep original value if conversion fails\n",
    "                        pass\n",
    "                        \n",
    "        return tool_call\n",
    "    \n",
    "    def run(self, user_input: str) -> str:\n",
    "        print(f\"{Fore.WHITE}{Style.BRIGHT}=== Starting agent run with user input: '{user_input}' ==={Style.RESET_ALL}\")\n",
    "        # Add user input to conversation history\n",
    "        self.conversation_history.append({\"role\": \"user\", \"content\": user_input})\n",
    "\n",
    "        # Build the messages list for OpenAI API\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": self.system_prompt + \"\\n\\n\" + self.format_tools_for_prompt()}\n",
    "        ]\n",
    "        \n",
    "        # Add conversation history\n",
    "        for message in self.conversation_history:\n",
    "            messages.append({\"role\": message[\"role\"], \"content\": message[\"content\"]})\n",
    "\n",
    "        # Get response from language model\n",
    "        print(f\"{Fore.CYAN}Calling language model...{Style.RESET_ALL}\")\n",
    "        response = self.model(model=\"gpt-4o\", messages=messages)\n",
    "        model_response = response.choices[0].message.content\n",
    "        print(f\"{Fore.CYAN}Received response from language model ({len(model_response)} chars){Style.RESET_ALL}\")\n",
    "\n",
    "        # Extract tool calls from response\n",
    "        tool_calls = self.extract_tool_calls(model_response)\n",
    "        \n",
    "        # If no tool calls, return the response directly\n",
    "        if not tool_calls:\n",
    "            print(f\"{Fore.GREEN}No tool calls needed. Returning response.{Style.RESET_ALL}\")\n",
    "            final_response = model_response\n",
    "        else:\n",
    "            # Execute tools and collect results\n",
    "            tool_results = []\n",
    "            for i, tool_call in enumerate(tool_calls):\n",
    "                print(f\"{Fore.MAGENTA}{Style.BRIGHT}Executing tool call {i+1}/{len(tool_calls)}{Style.RESET_ALL}\")\n",
    "                result = self.execute_tool(tool_call)\n",
    "                tool_results.append({\n",
    "                    \"tool\": tool_call.get(\"name\"),\n",
    "                    \"arguments\": tool_call.get(\"arguments\"),\n",
    "                    \"result\": result\n",
    "                })\n",
    "            \n",
    "            # Format tool results\n",
    "            results_text = \"Tool results:\\n\"\n",
    "            for res in tool_results:\n",
    "                result_str = str(res[\"result\"])\n",
    "                if isinstance(res[\"result\"], (dict, list)):\n",
    "                    try:\n",
    "                        result_str = json.dumps(res[\"result\"], indent=2)\n",
    "                    except:\n",
    "                        pass\n",
    "                    \n",
    "                results_text += f\"- {res['tool']}{json.dumps(res['arguments'])}: {result_str}\\n\"\n",
    "            \n",
    "            print(f\"{Fore.BLUE}Formatted tool results{Style.RESET_ALL}\")\n",
    "            \n",
    "            # Create a new message with original response and tool results\n",
    "            messages.append({\"role\": \"assistant\", \"content\": model_response})\n",
    "            messages.append({\"role\": \"user\", \"content\": results_text})\n",
    "            \n",
    "            # Get final response from language model with tool results\n",
    "            print(f\"{Fore.CYAN}Calling language model with tool results...{Style.RESET_ALL}\")\n",
    "            final_response_obj = self.model(model=\"gpt-4o\", messages=messages)\n",
    "            final_response = final_response_obj.choices[0].message.content\n",
    "            print(f\"{Fore.CYAN}Received final response from language model ({len(final_response)} chars){Style.RESET_ALL}\")\n",
    "        \n",
    "        # Add final response to conversation history\n",
    "        self.conversation_history.append({\n",
    "            \"role\": \"assistant\", \n",
    "            \"content\": final_response\n",
    "        })\n",
    "        \n",
    "        print(f\"{Fore.WHITE}{Style.BRIGHT}=== Agent run completed ===={Style.RESET_ALL}\")\n",
    "        return final_response\n",
    "        \n",
    "    def reset_conversation(self):\n",
    "        \"\"\"Clear the conversation history.\"\"\"\n",
    "        print(f\"{Fore.GREEN}Conversation history reset{Style.RESET_ALL}\")\n",
    "        self.conversation_history = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then bring in some other imports we will need for this session and create the LLM model we'll be using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReAct Agent System Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "REACT_SYSTEM_PROMPT = \"\"\"\n",
    "# ReAct Agent: Reasoning and Acting Framework\n",
    "\n",
    "You are an AI assistant that follows the ReAct (Reasoning and Acting) framework to solve problems. Your thinking process is structured in a clear cycle: Thought → Action → Observation.\n",
    "\n",
    "## How You Operate\n",
    "\n",
    "1. **THOUGHT**: Carefully reason about the problem and determine if a tool call is necessary\n",
    "2. **ACTION**: Execute tools based on your reasoning, following the proper format\n",
    "3. **OBSERVATION**: Analyze the results to inform your final response\n",
    "\n",
    "## Available Tools\n",
    "\n",
    "You have access to the following functions to help users:\n",
    "\n",
    "<tools>\n",
    "__TOOLS__\n",
    "</tools>\n",
    "\n",
    "## Tool Calling Format\n",
    "\n",
    "When you decide to use a tool, format your call exactly as follows:\n",
    "\n",
    "<tool_call>\n",
    "{\"name\": \"function_name\", \"arguments\": {\"param1\": \"value1\", \"param2\": \"value2\"}}\n",
    "</tool_call>\n",
    "\n",
    "For example, if you have a tool with this definition:\n",
    "\n",
    "<tool_call>\n",
    "{\n",
    "    \"name\": \"add_two_numbers\",\n",
    "    \"description\": \"Used to add two numbers together\",\n",
    "    \"parameters\": {\n",
    "        \"properties\": {\n",
    "            \"a\": {\n",
    "                \"type\": \"int\"\n",
    "            },\n",
    "            \"b\": {\n",
    "                \"type\": \"int\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "</tool_call>\n",
    "\n",
    "Your tool call should look like:\n",
    "\n",
    "<tool_call>\n",
    "{\"name\": \"add_two_numbers\", \"arguments\": {\"a\": 1, \"b\": 2}}\n",
    "</tool_call>\n",
    "\n",
    "## Interaction Flow\n",
    "\n",
    "Follow this structured approach to every user request:\n",
    "\n",
    "1. <thought>Your detailed reasoning about how to approach the problem</thought>\n",
    "2. <tool_call>Your properly formatted tool call if needed</tool_call>\n",
    "\n",
    "After your tool call, you will receive:\n",
    "\n",
    "<observation>Results from the tool execution</observation>\n",
    "\n",
    "Then provide your final answer:\n",
    "\n",
    "<response>Your complete, helpful answer based on the tool results</response>\n",
    "\n",
    "## Example Interaction\n",
    "\n",
    "<question>What's the sum of 10 and 20?</question>\n",
    "\n",
    "<thought>To answer this question, I need to get the sum of 10 and 20. I should use a tool to perform this calculation.</thought>\n",
    "<tool_call>{\"name\": \"add_two_numbers\", \"arguments\": {\"a\": 10, \"b\": 20}}</tool_call>\n",
    "\n",
    "[System provides tool result]\n",
    "<observation>{\"result\": 30}</observation>\n",
    "\n",
    "<response>The sum of 10 and 20 is 30.</response>\n",
    "\n",
    "## Important Guidelines\n",
    "\n",
    "- Always begin with a <thought> tag to show your reasoning process\n",
    "- Carefully inspect the function signature before making a tool call\n",
    "- Pay special attention to parameter types and requirements\n",
    "- Don't make assumptions about parameter values\n",
    "- Use proper JSON syntax in your tool calls\n",
    "- If a query doesn't require tools, respond directly:\n",
    "  <thought>This question doesn't require any tool use because...</thought>\n",
    "  <response>Your helpful answer here...</response>\n",
    "- For complex tasks that require multiple tools, use one tool at a time\n",
    "- If you receive unclear results, think about alternative approaches\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation of the ReAct Agent System Prompt\n",
    "\n",
    "This system prompt creates an AI agent that follows the Reasoning and Acting (ReAct) framework. Here's a breakdown of how it works and how to customize it:\n",
    "\n",
    "### XML Tags\n",
    "\n",
    "The prompt uses several custom XML tags to structure the agent's thought process and actions:\n",
    "\n",
    "1. `<thought>...</thought>` - Contains the agent's reasoning process before taking any actions\n",
    "2. `<tool_call>...</tool_call>` - Wraps the JSON for calling a specific function/tool\n",
    "3. `<observation>...</observation>` - Contains the results returned from tool execution\n",
    "4. `<response>...</response>` - Contains the agent's final answer to the user\n",
    "5. `<tools>...</tools>` - Defines all available tools the agent can use\n",
    "\n",
    "### The `__TOOLS__` Placeholder\n",
    "\n",
    "The `__TOOLS__` placeholder is where you'll inject the actual tool definitions before using the prompt. Here's how to replace it:\n",
    "\n",
    "1. Generate JSON definitions for each tool you want to make available\n",
    "2. Format each tool as a JSON object with `name`, `description`, and `parameters`\n",
    "3. Replace `__TOOLS__` with the string representation of these tool definitions\n",
    "\n",
    "For example, if you have two tools, you might replace it like this:\n",
    "\n",
    "```python\n",
    "tools = [\n",
    "    {\n",
    "        \"name\": \"calculate_area\",\n",
    "        \"description\": \"Calculate the area of a rectangle\",\n",
    "        \"parameters\": {\n",
    "            \"properties\": {\n",
    "                \"length\": {\"type\": \"float\"},\n",
    "                \"width\": {\"type\": \"float\"}\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"get_current_weather\",\n",
    "        \"description\": \"Get the current weather for a location\",\n",
    "        \"parameters\": {\n",
    "            \"properties\": {\n",
    "                \"location\": {\"type\": \"string\"},\n",
    "                \"unit\": {\"type\": \"string\"}\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# Convert tools to JSON string\n",
    "tools_json = json.dumps(tools, indent=2)\n",
    "\n",
    "# Replace __TOOLS__ in the prompt\n",
    "final_prompt = REACT_SYSTEM_PROMPT.replace(\"__TOOLS__\", tools_json)\n",
    "```\n",
    "\n",
    "### Agent Workflow\n",
    "\n",
    "The prompt creates an agent that:\n",
    "\n",
    "1. Takes in a user query\n",
    "2. Thinks through the problem (in `<thought>` tags)\n",
    "3. If needed, calls a tool (in `<tool_call>` tags)\n",
    "4. Receives results (in `<observation>` tags)\n",
    "5. Provides a final answer (in `<response>` tags)\n",
    "\n",
    "This structured approach ensures transparency in the agent's reasoning process and makes debugging easier, as you can see exactly why the agent chose to call a specific tool and how it interpreted the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ceating Tools\n",
    "\n",
    "We can now create some tools to use with our ReAct agent.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def add_two_numbers(a: int, b: int) -> int:\n",
    "    \"\"\"Used to add two numbers together\"\"\"\n",
    "    return a + b\n",
    "\n",
    "@tool\n",
    "def calculate_area_of_rectangle(length: float, width: float) -> float:\n",
    "    \"\"\"Used to calculate the area of a rectangle\"\"\"\n",
    "    return length * width"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can view the specification of the tools we created by calling the `.specification` attribute on the tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"name\": \"add_two_numbers\", \"description\": \"Used to add two numbers together\", \"parameters\": {\"properties\": {\"a\": {\"type\": \"int\"}, \"b\": {\"type\": \"int\"}}}}'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_two_numbers.specification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's get all the tool signatures or specifications and create a JSON string representation of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [add_two_numbers, calculate_area_of_rectangle]\n",
    "tools_mapping = {tool.name: tool for tool in tools}\n",
    "\n",
    "tools_specifications = \"\".join([tool.specification for tool in tools])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"name\": \"add_two_numbers\", \"description\": \"Used to add two numbers together\", \"parameters\": {\"properties\": {\"a\": {\"type\": \"int\"}, \"b\": {\"type\": \"int\"}}}}{\"name\": \"calculate_area_of_rectangle\", \"description\": \"Used to calculate the area of a rectangle\", \"parameters\": {\"properties\": {\"length\": {\"type\": \"float\"}, \"width\": {\"type\": \"float\"}}}}\n"
     ]
    }
   ],
   "source": [
    "print(tools_specifications)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now add this signature into our system prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "REACT_SYSTEM_PROMPT = REACT_SYSTEM_PROMPT.replace(\"__TOOLS__\", tools_specifications)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# ReAct Agent: Reasoning and Acting Framework\n",
      "\n",
      "You are an AI assistant that follows the ReAct (Reasoning and Acting) framework to solve problems. Your thinking process is structured in a clear cycle: Thought → Action → Observation.\n",
      "\n",
      "## How You Operate\n",
      "\n",
      "1. **THOUGHT**: Carefully reason about the problem and determine if a tool call is necessary\n",
      "2. **ACTION**: Execute tools based on your reasoning, following the proper format\n",
      "3. **OBSERVATION**: Analyze the results to inform your final response\n",
      "\n",
      "## Available Tools\n",
      "\n",
      "You have access to the following functions to help users:\n",
      "\n",
      "<tools>\n",
      "{\"name\": \"add_two_numbers\", \"description\": \"Used to add two numbers together\", \"parameters\": {\"properties\": {\"a\": {\"type\": \"int\"}, \"b\": {\"type\": \"int\"}}}}{\"name\": \"calculate_area_of_rectangle\", \"description\": \"Used to calculate the area of a rectangle\", \"parameters\": {\"properties\": {\"length\": {\"type\": \"float\"}, \"width\": {\"type\": \"float\"}}}}\n",
      "</tools>\n",
      "\n",
      "## Tool Calling Format\n",
      "\n",
      "When you decide to use a tool, format your call exactly as follows:\n",
      "\n",
      "<tool_call>\n",
      "{\"name\": \"function_name\", \"arguments\": {\"param1\": \"value1\", \"param2\": \"value2\"}}\n",
      "</tool_call>\n",
      "\n",
      "For example, if you have a tool with this definition:\n",
      "\n",
      "<tool_call>\n",
      "{\n",
      "    \"name\": \"add_two_numbers\",\n",
      "    \"description\": \"Used to add two numbers together\",\n",
      "    \"parameters\": {\n",
      "        \"properties\": {\n",
      "            \"a\": {\n",
      "                \"type\": \"int\"\n",
      "            },\n",
      "            \"b\": {\n",
      "                \"type\": \"int\"\n",
      "            }\n",
      "        }\n",
      "    }\n",
      "}\n",
      "</tool_call>\n",
      "\n",
      "Your tool call should look like:\n",
      "\n",
      "<tool_call>\n",
      "{\"name\": \"add_two_numbers\", \"arguments\": {\"a\": 1, \"b\": 2}}\n",
      "</tool_call>\n",
      "\n",
      "## Interaction Flow\n",
      "\n",
      "Follow this structured approach to every user request:\n",
      "\n",
      "1. <thought>Your detailed reasoning about how to approach the problem</thought>\n",
      "2. <tool_call>Your properly formatted tool call if needed</tool_call>\n",
      "\n",
      "After your tool call, you will receive:\n",
      "\n",
      "<observation>Results from the tool execution</observation>\n",
      "\n",
      "Then provide your final answer:\n",
      "\n",
      "<response>Your complete, helpful answer based on the tool results</response>\n",
      "\n",
      "## Example Interaction\n",
      "\n",
      "<question>What's the sum of 10 and 20?</question>\n",
      "\n",
      "<thought>To answer this question, I need to get the sum of 10 and 20. I should use a tool to perform this calculation.</thought>\n",
      "<tool_call>{\"name\": \"add_two_numbers\", \"arguments\": {\"a\": 10, \"b\": 20}}</tool_call>\n",
      "\n",
      "[System provides tool result]\n",
      "<observation>{\"result\": 30}</observation>\n",
      "\n",
      "<response>The sum of 10 and 20 is 30.</response>\n",
      "\n",
      "## Important Guidelines\n",
      "\n",
      "- Always begin with a <thought> tag to show your reasoning process\n",
      "- Carefully inspect the function signature before making a tool call\n",
      "- Pay special attention to parameter types and requirements\n",
      "- Don't make assumptions about parameter values\n",
      "- Use proper JSON syntax in your tool calls\n",
      "- If a query doesn't require tools, respond directly:\n",
      "  <thought>This question doesn't require any tool use because...</thought>\n",
      "  <response>Your helpful answer here...</response>\n",
      "- For complex tasks that require multiple tools, use one tool at a time\n",
      "- If you receive unclear results, think about alternative approaches\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(REACT_SYSTEM_PROMPT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = \"The sum of 10 and 20 is the width of a rectangle that is 100 units long. What is the area of the rectangle?\"\n",
    "\n",
    "user_prompt = [\n",
    "    {\"role\": \"system\", \"content\": REACT_SYSTEM_PROMPT},\n",
    "    {\"role\": \"user\", \"content\": f\"<question>{user_query}</question>\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=user_prompt,\n",
    ")\n",
    "\n",
    "formatted_response = response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<thought>To find the area of the rectangle, I first need to determine the width, which is given as the sum of 10 and 20. I should first calculate this sum and then use the calculated width and the given length to find the area of the rectangle.</thought>\n",
      "<tool_call>{\"name\": \"add_two_numbers\", \"arguments\": {\"a\": 10, \"b\": 20}}</tool_call>\n"
     ]
    }
   ],
   "source": [
    "print(formatted_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now execute the tool call that the LLM has suggested.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_response_to_dict(response_content: str) -> dict:\n",
    "    \"\"\"\n",
    "    Extracts all <tool_call> JSON blocks from the response_content and returns them as a list of dicts.\n",
    "    Handles errors gracefully.\n",
    "    \"\"\"\n",
    "    import re\n",
    "    import json\n",
    "\n",
    "    tool_calls = []\n",
    "    try:\n",
    "        # Find all <tool_call>...</tool_call> blocks\n",
    "        matches = re.findall(r\"<tool_call>\\s*(\\{.*?\\})\\s*</tool_call>\", response_content, re.DOTALL)\n",
    "        if not matches:\n",
    "            raise ValueError(\"No <tool_call> JSON found in response.\")\n",
    "\n",
    "        for match in matches:\n",
    "            try:\n",
    "                tool_calls.append(json.loads(match))\n",
    "            except json.JSONDecodeError as e:\n",
    "                tool_calls.append({\n",
    "                    \"name\": \"JSONDecodeError\",\n",
    "                    \"message\": f\"Error decoding JSON: {str(e)}\",\n",
    "                    \"raw\": match\n",
    "                })\n",
    "        return tool_calls\n",
    "    except Exception as e:\n",
    "        return [{\n",
    "            \"name\": type(e).__name__,\n",
    "            \"message\": str(e),\n",
    "            \"stack\": None\n",
    "        }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'add_two_numbers', 'arguments': {'a': 10, 'b': 20}}]\n"
     ]
    }
   ],
   "source": [
    "transformed_response = transform_response_to_dict(formatted_response)\n",
    "print(transformed_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool add_two_numbers executed with result: 30\n"
     ]
    }
   ],
   "source": [
    "tool_result = \"\"\n",
    "\n",
    "for tool_call in transformed_response:\n",
    "    tool_name = tool_call.get(\"name\")\n",
    "    tool = tools_mapping.get(tool_name)\n",
    "    if tool:\n",
    "        tool_result = tool.execute(**tool_call.get(\"arguments\", {}))\n",
    "        print(f\"Tool {tool_name} executed with result: {tool_result}\")\n",
    "    else:\n",
    "        print(f\"Tool {tool_name} not found in tools_mapping\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then send the tool results back to the LLM as part of the prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt.append({\"role\": \"user\", \"content\": f\"<observation>{tool_result}</observation>\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': '\\n# ReAct Agent: Reasoning and Acting Framework\\n\\nYou are an AI assistant that follows the ReAct (Reasoning and Acting) framework to solve problems. Your thinking process is structured in a clear cycle: Thought → Action → Observation.\\n\\n## How You Operate\\n\\n1. **THOUGHT**: Carefully reason about the problem and determine if a tool call is necessary\\n2. **ACTION**: Execute tools based on your reasoning, following the proper format\\n3. **OBSERVATION**: Analyze the results to inform your final response\\n\\n## Available Tools\\n\\nYou have access to the following functions to help users:\\n\\n<tools>\\n{\"name\": \"add_two_numbers\", \"description\": \"Used to add two numbers together\", \"parameters\": {\"properties\": {\"a\": {\"type\": \"int\"}, \"b\": {\"type\": \"int\"}}}}{\"name\": \"calculate_area_of_rectangle\", \"description\": \"Used to calculate the area of a rectangle\", \"parameters\": {\"properties\": {\"length\": {\"type\": \"float\"}, \"width\": {\"type\": \"float\"}}}}\\n</tools>\\n\\n## Tool Calling Format\\n\\nWhen you decide to use a tool, format your call exactly as follows:\\n\\n<tool_call>\\n{\"name\": \"function_name\", \"arguments\": {\"param1\": \"value1\", \"param2\": \"value2\"}}\\n</tool_call>\\n\\nFor example, if you have a tool with this definition:\\n\\n<tool_call>\\n{\\n    \"name\": \"add_two_numbers\",\\n    \"description\": \"Used to add two numbers together\",\\n    \"parameters\": {\\n        \"properties\": {\\n            \"a\": {\\n                \"type\": \"int\"\\n            },\\n            \"b\": {\\n                \"type\": \"int\"\\n            }\\n        }\\n    }\\n}\\n</tool_call>\\n\\nYour tool call should look like:\\n\\n<tool_call>\\n{\"name\": \"add_two_numbers\", \"arguments\": {\"a\": 1, \"b\": 2}}\\n</tool_call>\\n\\n## Interaction Flow\\n\\nFollow this structured approach to every user request:\\n\\n1. <thought>Your detailed reasoning about how to approach the problem</thought>\\n2. <tool_call>Your properly formatted tool call if needed</tool_call>\\n\\nAfter your tool call, you will receive:\\n\\n<observation>Results from the tool execution</observation>\\n\\nThen provide your final answer:\\n\\n<response>Your complete, helpful answer based on the tool results</response>\\n\\n## Example Interaction\\n\\n<question>What\\'s the sum of 10 and 20?</question>\\n\\n<thought>To answer this question, I need to get the sum of 10 and 20. I should use a tool to perform this calculation.</thought>\\n<tool_call>{\"name\": \"add_two_numbers\", \"arguments\": {\"a\": 10, \"b\": 20}}</tool_call>\\n\\n[System provides tool result]\\n<observation>{\"result\": 30}</observation>\\n\\n<response>The sum of 10 and 20 is 30.</response>\\n\\n## Important Guidelines\\n\\n- Always begin with a <thought> tag to show your reasoning process\\n- Carefully inspect the function signature before making a tool call\\n- Pay special attention to parameter types and requirements\\n- Don\\'t make assumptions about parameter values\\n- Use proper JSON syntax in your tool calls\\n- If a query doesn\\'t require tools, respond directly:\\n  <thought>This question doesn\\'t require any tool use because...</thought>\\n  <response>Your helpful answer here...</response>\\n- For complex tasks that require multiple tools, use one tool at a time\\n- If you receive unclear results, think about alternative approaches\\n'},\n",
       " {'role': 'user',\n",
       "  'content': '<question>The sum of 10 and 20 is the width of a rectangle that is 100 units long. What is the area of the rectangle?</question>'},\n",
       " {'role': 'user', 'content': '<observation>\"\"</observation>'},\n",
       " {'role': 'user', 'content': '<observation>\"\"</observation>'},\n",
       " {'role': 'user', 'content': '<observation>30</observation>'}]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=user_prompt,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the output above, we can see the LLM now wants to calculate the area of the rectangle. This is since the tool call has been executed and the result has been returned for the addition of 10 and 20. Powered with this information, the LLM can now calculate the area of the rectangle.\n",
    "\n",
    "This is the Observation bit of a ReAct agent. Action, Observation, Thought, Response if no further tool calls are needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<response>The sum of 10 and 20 is 30, which is the width of the rectangle. To find the area of the rectangle, I will multiply the width by the length. Let's calculate that.</response>\n",
      "\n",
      "<thought>The width of the rectangle is 30 units and the length is 100 units. I should use the tool to calculate the area of the rectangle.</thought>\n",
      "<tool_call>{\"name\": \"calculate_area_of_rectangle\", \"arguments\": {\"length\": 100, \"width\": 30}}</tool_call>\n"
     ]
    }
   ],
   "source": [
    "formatted_response = response.choices[0].message.content\n",
    "print(formatted_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'calculate_area_of_rectangle', 'arguments': {'length': 100, 'width': 30}}]\n"
     ]
    }
   ],
   "source": [
    "transformed_response = transform_response_to_dict(formatted_response)\n",
    "print(transformed_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool calculate_area_of_rectangle executed with result: 3000\n"
     ]
    }
   ],
   "source": [
    "tool_result = \"\"\n",
    "\n",
    "for tool_call in transformed_response:\n",
    "    tool_name = tool_call.get(\"name\")\n",
    "    tool = tools_mapping.get(tool_name)\n",
    "    if tool:\n",
    "        tool_result = tool.execute(**tool_call.get(\"arguments\", {}))\n",
    "        print(f\"Tool {tool_name} executed with result: {tool_result}\")\n",
    "    else:\n",
    "        print(f\"Tool {tool_name} not found in tools_mapping\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt.append({\"role\": \"user\", \"content\": f\"<observation>{tool_result}</observation>\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=user_prompt,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<response>The area of the rectangle with a length of 100 units and a width of 30 units is 3000 square units.</response>\n"
     ]
    }
   ],
   "source": [
    "formatted_response = response.choices[0].message.content\n",
    "print(formatted_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from typing import Callable, List, Dict, Any\n",
    "from colorama import init, Fore, Style\n",
    "\n",
    "init(autoreset=True)\n",
    "\n",
    "class Tool:\n",
    "    def __init__(self, name: str, function: Callable, specification: str):\n",
    "        self.name = name\n",
    "        self.function = function\n",
    "        self.specification = specification\n",
    "\n",
    "    def execute(self, **kwargs):\n",
    "        return self.function(**kwargs)\n",
    "\n",
    "def extract_function_metadata(function: Callable) -> Dict[str, Any]:\n",
    "    metadata = {\n",
    "        \"name\": function.__name__,\n",
    "        \"description\": function.__doc__,\n",
    "        \"parameters\": {\"properties\": {}}\n",
    "    }\n",
    "    parameter_types = {\n",
    "        param_name: {\"type\": param_type.__name__}\n",
    "        for param_name, param_type in function.__annotations__.items()\n",
    "        if param_name != \"return\"\n",
    "    }\n",
    "    metadata[\"parameters\"][\"properties\"] = parameter_types\n",
    "    return metadata\n",
    "\n",
    "def tool(function: Callable) -> Tool:\n",
    "    metadata = extract_function_metadata(function)\n",
    "    return Tool(\n",
    "        name=metadata.get(\"name\"),\n",
    "        function=function,\n",
    "        specification=json.dumps(metadata)\n",
    "    )\n",
    "\n",
    "class ReActAgent:\n",
    "    def __init__(self, llm: Callable, system_prompt: str, tools: List[Tool], max_iterations: int = 10):\n",
    "        self.llm = llm\n",
    "        self.system_prompt = system_prompt\n",
    "        self.tools = {tool.name: tool for tool in tools}\n",
    "        self.conversation_history = []\n",
    "        self.max_iterations = max_iterations\n",
    "\n",
    "    def format_tools_for_prompt(self) -> str:\n",
    "        tools_json = [json.loads(tool.specification) for tool in self.tools.values()]\n",
    "        return f\"<tools>\\n{json.dumps(tools_json, indent=2)}\\n</tools>\"\n",
    "\n",
    "    def extract_tool_calls(self, response: str) -> List[Dict[str, Any]]:\n",
    "        tool_calls = []\n",
    "        pattern = r\"<tool_call>(.*?)</tool_call>\"\n",
    "        matches = re.findall(pattern, response, re.DOTALL)\n",
    "        for match in matches:\n",
    "            try:\n",
    "                tool_call = json.loads(match.strip())\n",
    "                if \"name\" in tool_call and \"arguments\" in tool_call:\n",
    "                    tool_calls.append(tool_call)\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"{Fore.RED}Failed to decode tool call: {match}{Style.RESET_ALL}\")\n",
    "                continue\n",
    "        return tool_calls\n",
    "\n",
    "    def extract_final_response(self, response: str) -> str:\n",
    "        match = re.search(r\"<response>(.*?)</response>\", response, re.DOTALL)\n",
    "        if match:\n",
    "            return match.group(1).strip()\n",
    "        return None\n",
    "\n",
    "    def convert_argument_types(self, tool_call: Dict[str, Any], tool_spec: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        if \"parameters\" not in tool_spec or \"properties\" not in tool_spec[\"parameters\"]:\n",
    "            return tool_call\n",
    "        properties = tool_spec[\"parameters\"][\"properties\"]\n",
    "        type_mapping = {\n",
    "            \"int\": int,\n",
    "            \"str\": str,\n",
    "            \"bool\": bool,\n",
    "            \"float\": float,\n",
    "            \"integer\": int,\n",
    "            \"string\": str,\n",
    "            \"boolean\": bool,\n",
    "            \"number\": float\n",
    "        }\n",
    "        for arg_name, arg_value in tool_call[\"arguments\"].items():\n",
    "            if arg_name in properties and \"type\" in properties[arg_name]:\n",
    "                expected_type = properties[arg_name][\"type\"]\n",
    "                if expected_type in type_mapping:\n",
    "                    converter = type_mapping[expected_type]\n",
    "                    try:\n",
    "                        if not isinstance(arg_value, converter):\n",
    "                            print(f\"{Fore.BLUE}Converting argument '{arg_name}' from {type(arg_value).__name__} to {expected_type}{Style.RESET_ALL}\")\n",
    "                            tool_call[\"arguments\"][arg_name] = converter(arg_value)\n",
    "                    except (ValueError, TypeError) as e:\n",
    "                        print(f\"{Fore.RED}Type conversion error for '{arg_name}': {str(e)}{Style.RESET_ALL}\")\n",
    "                        pass\n",
    "        return tool_call\n",
    "\n",
    "    def execute_tool(self, tool_call: Dict[str, Any]) -> Any:\n",
    "        tool_name = tool_call.get(\"name\")\n",
    "        arguments = tool_call.get(\"arguments\", {})\n",
    "        if tool_name not in self.tools:\n",
    "            print(f\"{Fore.RED}Error: Tool '{tool_name}' not found{Style.RESET_ALL}\")\n",
    "            return f\"Error: Tool '{tool_name}' not found\"\n",
    "        tool = self.tools[tool_name]\n",
    "        print(f\"{Fore.MAGENTA}Executing tool: {tool_name} with arguments: {json.dumps(arguments)}{Style.RESET_ALL}\")\n",
    "        try:\n",
    "            tool_spec = json.loads(tool.specification)\n",
    "            validated_args = self.convert_argument_types({\"arguments\": arguments}, tool_spec)[\"arguments\"]\n",
    "            arguments = validated_args\n",
    "        except Exception as e:\n",
    "            print(f\"{Fore.RED}Error validating arguments: {str(e)}{Style.RESET_ALL}\")\n",
    "            pass\n",
    "        try:\n",
    "            result = tool.execute(**arguments)\n",
    "            print(f\"{Fore.GREEN}Tool '{tool_name}' executed successfully. Result: {result}{Style.RESET_ALL}\")\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            print(f\"{Fore.RED}Error executing {tool_name}: {str(e)}{Style.RESET_ALL}\")\n",
    "            return f\"Error executing {tool_name}: {str(e)}\"\n",
    "\n",
    "    def run(self, user_input: str) -> str:\n",
    "        self.conversation_history.append({\"role\": \"user\", \"content\": user_input})\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": self.system_prompt + \"\\n\\n\" + self.format_tools_for_prompt()}\n",
    "        ]\n",
    "        for message in self.conversation_history:\n",
    "            messages.append({\"role\": message[\"role\"], \"content\": message[\"content\"]})\n",
    "\n",
    "        iterations = 0\n",
    "        last_response = None\n",
    "\n",
    "        while iterations < self.max_iterations:\n",
    "            iterations += 1\n",
    "            print(f\"{Fore.CYAN}{Style.BRIGHT}--- Iteration {iterations} ---{Style.RESET_ALL}\")\n",
    "\n",
    "            # Get response from language model\n",
    "            response = self.llm(model=\"gpt-4o\", messages=messages)\n",
    "            model_response = response.choices[0].message.content\n",
    "            print(f\"{Fore.YELLOW}Model response:\\n{model_response}{Style.RESET_ALL}\")\n",
    "\n",
    "            # Check for final response\n",
    "            final_response = self.extract_final_response(model_response)\n",
    "            if final_response is not None:\n",
    "                # print(f\"{Fore.GREEN}{Style.BRIGHT}Final response found!{Style.RESET_ALL}\")\n",
    "                self.conversation_history.append({\"role\": \"assistant\", \"content\": model_response})\n",
    "                return final_response\n",
    "\n",
    "            # Extract tool calls from response\n",
    "            tool_calls = self.extract_tool_calls(model_response)\n",
    "            if not tool_calls:\n",
    "                print(f\"{Fore.GREEN}No tool calls found. Returning model response.{Style.RESET_ALL}\")\n",
    "                self.conversation_history.append({\"role\": \"assistant\", \"content\": model_response})\n",
    "                return model_response\n",
    "\n",
    "            # Execute tools and collect results\n",
    "            tool_results = []\n",
    "            for i, tool_call in enumerate(tool_calls):\n",
    "                print(f\"{Fore.MAGENTA}{Style.BRIGHT}Executing tool call {i+1}/{len(tool_calls)}{Style.RESET_ALL}\")\n",
    "                result = self.execute_tool(tool_call)\n",
    "                tool_results.append({\n",
    "                    \"tool\": tool_call.get(\"name\"),\n",
    "                    \"arguments\": tool_call.get(\"arguments\"),\n",
    "                    \"result\": result\n",
    "                })\n",
    "\n",
    "            # Format tool results for the next prompt\n",
    "            results_text = \"Tool results:\\n\"\n",
    "            for res in tool_results:\n",
    "                result_str = str(res[\"result\"])\n",
    "                if isinstance(res[\"result\"], (dict, list)):\n",
    "                    try:\n",
    "                        result_str = json.dumps(res[\"result\"], indent=2)\n",
    "                    except Exception:\n",
    "                        pass\n",
    "                results_text += f\"- {res['tool']}{json.dumps(res['arguments'])}: {result_str}\\n\"\n",
    "\n",
    "            print(f\"{Fore.BLUE}Tool results to be sent to LLM:\\n{results_text}{Style.RESET_ALL}\")\n",
    "\n",
    "            # Add model response and tool results to messages for next iteration\n",
    "            messages.append({\"role\": \"assistant\", \"content\": model_response})\n",
    "            messages.append({\"role\": \"user\", \"content\": results_text})\n",
    "\n",
    "        print(f\"{Fore.RED}Max iterations reached without a final response.{Style.RESET_ALL}\")\n",
    "        return \"Max iterations reached without a final response.\"\n",
    "\n",
    "    def reset_conversation(self):\n",
    "        print(f\"{Fore.GREEN}Conversation history reset{Style.RESET_ALL}\")\n",
    "        self.conversation_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iteration 1 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model response:\n",
      "<thought>To find the area of the rectangle, I need to calculate its width by summing 10 and 20. Then, I will use the width and the given length to calculate the area of the rectangle using the appropriate tool.</thought>\n",
      "\n",
      "<tool_call>{\"name\": \"add_two_numbers\", \"arguments\": {\"a\": 10, \"b\": 20}}</tool_call>\n",
      "Executing tool call 1/1\n",
      "Executing tool: add_two_numbers with arguments: {\"a\": 10, \"b\": 20}\n",
      "Tool 'add_two_numbers' executed successfully. Result: 30\n",
      "Tool results to be sent to LLM:\n",
      "Tool results:\n",
      "- add_two_numbers{\"a\": 10, \"b\": 20}: 30\n",
      "\n",
      "--- Iteration 2 ---\n",
      "Model response:\n",
      "<observation>{\"result\": 30}</observation>\n",
      "\n",
      "<thought>The width of the rectangle is 30 units. Now that I have both the length (100 units) and the width (30 units), I can calculate the area of the rectangle.</thought>\n",
      "<tool_call>{\"name\": \"calculate_area_of_rectangle\", \"arguments\": {\"length\": 100.0, \"width\": 30.0}}</tool_call>\n",
      "Executing tool call 1/1\n",
      "Executing tool: calculate_area_of_rectangle with arguments: {\"length\": 100.0, \"width\": 30.0}\n",
      "Tool 'calculate_area_of_rectangle' executed successfully. Result: 3000.0\n",
      "Tool results to be sent to LLM:\n",
      "Tool results:\n",
      "- calculate_area_of_rectangle{\"length\": 100.0, \"width\": 30.0}: 3000.0\n",
      "\n",
      "--- Iteration 3 ---\n",
      "Model response:\n",
      "<observation>{\"result\": 3000.0}</observation>\n",
      "\n",
      "<response>The area of the rectangle is 3000 square units.</response>\n",
      "The area of the rectangle is 3000 square units.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# Define your tools\n",
    "@tool\n",
    "def add_two_numbers(a: int, b: int) -> int:\n",
    "    \"\"\"Used to add two numbers together\"\"\"\n",
    "    return a + b\n",
    "\n",
    "@tool\n",
    "def calculate_area_of_rectangle(length: float, width: float) -> float:\n",
    "    \"\"\"Used to calculate the area of a rectangle\"\"\"\n",
    "    return length * width\n",
    "\n",
    "tools = [add_two_numbers, calculate_area_of_rectangle]\n",
    "\n",
    "# Prepare your system prompt (replace __TOOLS__ as in your notebook)\n",
    "tools_json = json.dumps([json.loads(t.specification) for t in tools], indent=2)\n",
    "REACT_SYSTEM_PROMPT = REACT_SYSTEM_PROMPT.replace(\"__TOOLS__\", tools_json)\n",
    "\n",
    "# Create OpenAI client\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))  # Or use os.getenv\n",
    "\n",
    "# Create the agent\n",
    "agent = ReActAgent(\n",
    "    llm=client.chat.completions.create,\n",
    "    system_prompt=REACT_SYSTEM_PROMPT,\n",
    "    tools=tools\n",
    ")\n",
    "\n",
    "# Run the agent\n",
    "result = agent.run(\"The sum of 10 and 20 is the width of a rectangle that is 100 units long. What is the area of the rectangle?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multi-agent-patterns-from-scratch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
